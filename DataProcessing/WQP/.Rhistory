###################################*
#### Account for Multiple Results ####
###################################*
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate','DataLoggerLine',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
wq_data=wq_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 49418 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
nrow(wq_data) - nrow(unique(tmp)) # 5569 - multiple results
# *NOTE:*
# Some records have one or more unique result value. These are flagged in processed data w/ result_count column.
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 49418 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 49422 xx
wq_data[,.N,by=result_count]
#    result_count     N
# 1:            1 40123
# 2:            2  5176
# 3:            3  1902
# 4:            4  1384
# 5:            5   695
# 6:            6    96
# 7:           13    13
# 8:           12    12
# 9:           21    21
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
fwrite(wq_data,paste0('ArchivedProcessedDatasets/wq_data_wqp_processed_',Sys.Date(),'.csv'))
save(wq_data,file=paste0('ArchivedProcessedDatasets/wq_data_',Sys.Date(),'.RData'))
dim(wq_data) # 49422 xx
# Clean workspace
rm(list=ls()); gc()
# Utah Lake site list
auid_list=c('UT-L-16020201-004_02','UT-L-16020201-004_01')
# Read Utah Lake site locations  & generate site map
# Note: Connection to WQP occasionally times out. Function tries connection up to 10 times.
ul_sites=wqTools::readWQP(type='sites',auid=auid_list,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water')
setDT(ul_sites)
# Make syntactically correct field names
names(ul_sites)=gsub(' ','', names(ul_sites))
# Drop fields that are contained in ul_nr
ul_sites[,OrganizationIdentifier:=NULL]
ul_sites[,OrganizationFormalName:=NULL]
ul_sites[,ProviderName:=NULL]
# Load packages
# devtools::install_github('utah-dwq/wqTools')
library(wqTools)
library(data.table)
setDT(ul_sites)
# Make syntactically correct field names
names(ul_sites)=gsub(' ','', names(ul_sites))
# Drop fields that are contained in ul_nr
ul_sites[,OrganizationIdentifier:=NULL]
ul_sites[,OrganizationFormalName:=NULL]
ul_sites[,ProviderName:=NULL]
# Generate site map
map=wqTools::buildMap(sites=ul_sites,plot_polys=F)
map=leaflet::setView(map,lng=median(ul_sites$LongitudeMeasure),lat=median(ul_sites$LatitudeMeasure),zoom=10)
map
ul_nr=wqTools::readWQP(type='narrowresult',auid=auid_list,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water',print=F)
ul_act=wqTools::readWQP(type='activity',auid=auid_list,sampleMedia='Water')
ul_dql=wqTools::readWQP(type='detquantlim',auid=auid_list,sampleMedia='Water')
# Check that all 4 WQP components were downloaded
if(!all(exists('ul_sites'),exists('ul_nr'),exists('ul_act'),exists('ul_dql'))) print('STOP - WQP component(s) did not download.')
# Convert to data.tables
setDT(ul_nr)
setDT(ul_act)
setDT(ul_dql)
# Make syntactically correct field names
names(ul_nr)=gsub(' ','', names(ul_nr))
names(ul_act)=gsub(' ','', names(ul_act))
names(ul_dql)=gsub(' ','', names(ul_dql))
# Pivot ul_dql on "detection limit type"
dql_vals=dcast(ul_dql,ResultIdentifier~DetectionQuantitationLimitTypeName,value.var='DetectionQuantitationLimitMeasure.MeasureValue')
# Pivot ul_dql on "Units"
dql_units=dcast(ul_dql,ResultIdentifier~DetectionQuantitationLimitTypeName,value.var='DetectionQuantitationLimitMeasure.MeasureUnitCode')
# Make syntactically correct field names
names(dql_vals)=gsub(' ','', names(dql_vals))
names(dql_units)=gsub(' ','', names(dql_units))
# Edit dql_units names
tmp=paste0(names(dql_units),'Unit')
tmp[1]='ResultIdentifier'
names(dql_units)=tmp
cbind(names(dql_units),tmp)
# Join detection type and units
intersect(names(dql_vals),names(dql_units))
ul_dql_wide=merge(dql_vals,dql_units,by='ResultIdentifier',all=F) # Inner join (Left/Right Outer join also works)
# Drop fields from ul_nr that are in ul_act
ul_nr[,ActivityStartDate:=NULL]
ul_nr[,ActivityStartTime.Time:=NULL]
ul_nr[,ActivityStartTime.TimeZoneCode:=NULL]
# Drop fields from ul_act that are in ul_nr
ul_nr[,OrganizationIdentifier:=NULL]
ul_nr[,OrganizationFormalName:=NULL]
ul_nr[,MonitoringLocationIdentifier:=NULL]
ul_nr[,ProviderName:=NULL]
# Join activity metadata data to narrowresult
intersect(names(ul_nr),names(ul_act))
wq_data=merge(ul_nr,ul_act,by='ActivityIdentifier',all.x=T) # Left outer join
dim(wq_data) # 54862 xx
# Convert to Date
wq_data[,ActivityStartDate:=as.Date(ActivityStartDate,format='%Y-%m-%d')]
# Join site data to narrowresult
intersect(names(wq_data),names(ul_sites))
wq_data=merge(wq_data,ul_sites,by='MonitoringLocationIdentifier',all.x=T) # Left outer join
# Join detection/quantification limit data to narrowresult
intersect(names(wq_data),names(ul_dql_wide))
wq_data=merge(wq_data,ul_dql_wide,by='ResultIdentifier',all.x=T) # Left outer join
# Write raw, as queried data from EPA WQP
fwrite(wq_data,paste0('ArchivedRawDatasets/ul_data_wqp_raw_',Sys.Date(),'.csv'))
dim(wq_data) # 54862 xx
# Remove QA/QC field replicate site
wq_data=wq_data[MonitoringLocationIdentifier!='UTAHDWQ_WQX-4917320',]
dim(wq_data) # 51405 xx
# Check field parameters for activity types
field_params=c('pH','Specific conductance','Dissolved oxygen (DO)','Dissolved oxygen saturation','Temperature,water')
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Remove lab data for field parameters
wq_data=wq_data[!(CharacteristicName %in% field_params &
ActivityTypeCode %in% c('Sample-Routine','Sample-Integrated Vertical Profile','Quality Control Sample-Field Replicate')),]
dim(wq_data) # 50829 xx
# (double) Check field parameters for activity types
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Merge ActivityDepth and ResultDepth values to a new column
wq_data[,SampleDepthValue:=ActivityDepthHeightMeasure.MeasureValue] # Reset
wq_data[is.na(SampleDepthValue),SampleDepthValue:=ResultDepthHeightMeasure.MeasureValue]
# Merge ActivityDepth and ResultDepth units to a new column
wq_data[,SampleDepthUnit:=ActivityDepthHeightMeasure.MeasureUnitCode] # Reset
wq_data[is.na(SampleDepthUnit),SampleDepthUnit:=ResultDepthHeightMeasure.MeasureUnitCode]
# *NOTE:*
# Many records missing both depth fields have a RelativeDepth filled in which could potentially be used to fill in values.
# Others are for CharacteristicName == 'Depth, data-logger (ported)' and can be filled with the result value and unit.
wq_data[,.N,by=.(is.na(SampleDepthValue) & is.na(ActivityRelativeDepthName))]
#    is.na     N
# 1:  TRUE  5432
# 2: FALSE 45397
# knitr::kable(table(is.na(wq_data$SampleDepthValue) & is.na(wq_data$ActivityRelativeDepthName)))
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
# Fill sample depths and units for CharacteristicName 'Depth, data-logger (ported)'
wq_data[is.na(SampleDepthValue) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthValue:=ResultMeasureValue]
wq_data[is.na(SampleDepthUnit) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthUnit:=ResultMeasure.MeasureUnitCode]
# Check SampleDepthValue
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
# Setting SampleDepthValue to NA for records w/ ActivityRelativeDepthName=='Bottom' & ActivityDepthHeight==0
wq_data[ActivityRelativeDepthName=='Bottom' & ActivityDepthHeightMeasure.MeasureValue==0,SampleDepthValue:=NA]
# Generating new RelativeDepth column for cases where both ActivityDepth and ResultDepth are NULL
wq_data[,RelativeDepth:=NA_character_] # Reset
wq_data[is.na(SampleDepthValue) & !is.na(ActivityRelativeDepthName),RelativeDepth:=ActivityRelativeDepthName]
# Extract times by site & date
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2215 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data (by site & date)
intersect(names(wq_data),names(site_date_starttime))
wq_data=merge(wq_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(wq_data) # 50829 xx
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
wq_data=wq_data[,..cols_keep]
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 49418 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
nrow(wq_data) - nrow(unique(tmp)) # 5569 - multiple results
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 49418 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 49422 xx
wq_data[,.N,by=result_count]
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Export to csv and RData
# Note: Files below are names "ul_data" to avoid confusion with the final processed "wq_data.RData" file.
fwrite(wq_data,paste0('ArchivedProcessedDatasets/ul_data_wqp_processed_',Sys.Date(),'.csv'))
save(wq_data,file=paste0('ArchivedProcessedDatasets/ul_data_',Sys.Date(),'.RData'))
# OVERWRITE existing "wq_data" object in parent directory.
# THIS WILL overwrite the .RData file that is the input to the Shiny app.
save(wq_data,file='ul_data.RData')
options(digits=7L)
par(mar=c(4.5,4.5,1,1),bty='l')
# devtools::install_github('utah-dwq/wqTools')
library(wqTools)
library(data.table)
# detach(package:aaa,unload=T)
# Clean workspace
rm(list=ls()); gc()
# Global settings
na.strings=c(NA,'NA','N/A','#N/A','na','-88','',' ','None','none','<Null>')
seed=27709L
# Utah Lake site list
auid_list=c('UT-L-16020201-004_02','UT-L-16020201-004_01')
# Read Utah Lake site locations  & generate site map
# Note: Connection to WQP occasionally times out. Function tries connection up to 10 times.
ul_sites=wqTools::readWQP(type='sites',auid=auid_list,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water')
# Utah Lake site list xxx
auid=c('UT-L-16020201-004_02','UT-L-16020201-004_01')
rm(auid_list)
ul_sites
class(ul_sites)
setDT(ul_sites)
ul_sites
dim(ul_sites) # aaa xx
?make.names
View(ul_sites)
rm(ul_sites)
# Read Utah Lake site locations  & generate site map xxx
# Note: Connection to WQP occasionally times out. Function tries connection up to 10 times.
sites=wqTools::readWQP(type='sites',auid=auid,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water')
setDT(sites)
dim(sites) # 68 xx
make.names(names(sites))
names(sites)
names(sites)==make.names(names(sites))
# Read Utah Lake site locations  & generate site map xxx
# Note: Connection to WQP occasionally times out. Function tries connection up to 10 times.
ul_sites=wqTools::readWQP(type='ul_sites',auid=auid,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water')
setDT(ul_sites)
# Read Utah Lake site locations  & generate site map xxx
# Note: Connection to WQP occasionally times out. Function tries connection up to 10 times.
ul_sites=wqTools::readWQP(type='sites',auid=auid,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water')
setDT(ul_sites)
dim(ul_sites) # 68 xx
rm(sites)
?readWQP
# Drop fields that are contained in ul_nr xxx
ul_sites[,OrganizationIdentifier:=NULL]
ul_sites[,OrganizationFormalName:=NULL]
ul_sites[,ProviderName:=NULL]
# Generate site map
map=wqTools::buildMap(ul_sites=ul_sites,plot_polys=F)
# Generate site map
map=wqTools::buildMap(sites=ul_sites,plot_polys=F)
map=leaflet::setView(map,lng=median(ul_sites$LongitudeMeasure),lat=median(ul_sites$LatitudeMeasure),zoom=10)
map
png('Map_Sites.png',width=5,height=7,units='in',res=300,type='cairo',pointsize=9)
map
dev.off()
# Export to png
png('Map_Sites.png',width=5,height=7,units='in',res=300,type='cairo',pointsize=9)
print(map)
dev.off()
plot(1)
# Export to png
png('Map_Sites.png',width=5,height=7,units='in',res=300,type='cairo',pointsize=9)
plot(1)
dev.off()
library(leaflet)
library(mapview)
mapshot(map,file='Map_Sites.png')
?mapshot
?readWQP
?setView
# Download WQP components xxx
ul_nr=readWQP(type='narrowresult',auid=auid,siteType=c('Lake, Reservoir, Impoundment'),sampleMedia='Water',print=F)
ul_act=readWQP(type='activity',auid=auid,sampleMedia='Water')
ul_dql=readWQP(type='detquantlim',auid=auid,sampleMedia='Water')
# Check that all 4 WQP components were downloaded
if(!all(exists('ul_sites'),exists('ul_nr'),exists('ul_act'),exists('ul_dql'))) print('STOP - WQP component(s) did not download.')
# Convert to data.tables
setDT(ul_nr)
setDT(ul_act)
setDT(ul_dql)
# Dims
dim(ul_nr)  # aaa xx
dim(ul_dql) # aaa xx
dim(ul_act) # aaa xx
View(ul_nr)
names(ul_nr)
?make.names
?dcast
# Pivot ul_dql on "detection limit type"
dql_vals=dcast(ul_dql,ResultIdentifier~DetectionQuantitationLimitTypeName,value.var='DetectionQuantitationLimitMeasure.MeasureValue')
dim(dql_vals) # aaa xx
dql_vals
# Pivot ul_dql on "detection limit type"
dql_vals=dcast(ul_dql,ResultIdentifier~DetectionQuantitationLimitTypeName,fun.aggregate=NULL,value.var='DetectionQuantitationLimitMeasure.MeasureValue')
dim(dql_vals) # 21101 xx
dql_vals
# Pivot ul_dql on "Units"
dql_units=dcast(ul_dql,ResultIdentifier~DetectionQuantitationLimitTypeName,fun.aggregate=NULL,value.var='DetectionQuantitationLimitMeasure.MeasureUnitCode')
dim(dql_units) # 21101 xx
names(dql_vals)
# Make syntactically correct field names (don't use make.names())
names(dql_vals)=gsub(' ','', names(dql_vals))
names(dql_units)=gsub(' ','', names(dql_units))
# Edit dql_units names
tmp=paste0(names(dql_units),'Unit')
tmp
tmp[1]='ResultIdentifier'
cbind(names(dql_units),tmp)
names(dql_units)=tmp
# Join detection type and units
intersect(names(dql_vals),names(dql_units))
ul_dql_wide=merge(dql_vals,dql_units,by='ResultIdentifier',all=F) # Inner join
# Drop fields from ul_nr that are in ul_act
ul_nr[,ActivityStartDate:=NULL]
ul_nr[,ActivityStartTime.Time:=NULL]
ul_nr[,ActivityStartTime.TimeZoneCode:=NULL]
# Drop fields from ul_act that are in ul_nr
ul_nr[,OrganizationIdentifier:=NULL]
ul_nr[,OrganizationFormalName:=NULL]
ul_nr[,MonitoringLocationIdentifier:=NULL]
ul_nr[,ProviderName:=NULL]
# Join activity metadata data to narrowresult
intersect(names(ul_nr),names(ul_act))
wq_data=merge(ul_nr,ul_act,by='ActivityIdentifier',all.x=T) # Left outer join
dim(wq_data) # 54862 xx
# Convert to Date
wq_data[,ActivityStartDate:=as.Date(ActivityStartDate,format='%Y-%m-%d')]
head(wq_data$ActivityStartDate)
# Join site data to narrowresult
intersect(names(wq_data),names(ul_sites))
wq_data=merge(wq_data,ul_sites,by='MonitoringLocationIdentifier',all.x=T) # Left outer join
# Join detection/quantification limit data to narrowresult
intersect(names(wq_data),names(ul_dql_wide))
wq_data=merge(wq_data,ul_dql_wide,by='ResultIdentifier',all.x=T) # Left outer join
dim(ul_dql_wide) # aaa xx
# Remove QA/QC field replicate site
wq_data=wq_data[MonitoringLocationIdentifier!='UTAHDWQ_WQX-4917320',]
dim(wq_data) # 51405 xx
gc()
save.image()
dim(wq_data) # 63395 xx
# Check field parameters for activity types xxx
field_params=c('pH','Specific conductance','Dissolved oxygen (DO)','Dissolved oxygen saturation','Temperature,water')
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Remove lab data for field parameters
wq_data=wq_data[!(CharacteristicName %in% field_params &
ActivityTypeCode %in% c('Sample-Routine','Sample-Integrated Vertical Profile','Quality Control Sample-Field Replicate')),]
dim(wq_data) # 50829 xx
# Check field parameters for activity types
wq_data[CharacteristicName %in% field_params,.N,by=ActivityTypeCode]
# Merge ActivityDepth and ResultDepth values to a new column xxx
wq_data[,SampleDepthValue:=ActivityDepthHeightMeasure.MeasureValue]
wq_data[is.na(SampleDepthValue),SampleDepthValue:=ResultDepthHeightMeasure.MeasureValue]
# Merge ActivityDepth and ResultDepth units to a new column
wq_data[,SampleDepthUnit:=ActivityDepthHeightMeasure.MeasureUnitCode]
wq_data[is.na(SampleDepthUnit),SampleDepthUnit:=ResultDepthHeightMeasure.MeasureUnitCode]
# *NOTE:*
# Many records missing both depth fields have a RelativeDepth filled in which could potentially be used to fill in values.
# Others are for CharacteristicName == 'Depth, data-logger (ported)' and can be filled with the result value and unit.
wq_data[,.N,by=.(is.na(SampleDepthValue) & is.na(ActivityRelativeDepthName))]
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
# Fill sample depths and units for CharacteristicName 'Depth, data-logger (ported)'
wq_data[is.na(SampleDepthValue) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthValue:=ResultMeasureValue]
wq_data[is.na(SampleDepthUnit) & CharacteristicName == 'Depth, data-logger (ported)',
SampleDepthUnit:=ResultMeasure.MeasureUnitCode]
# Check SampleDepthValue
wq_data[,.N,by=.(is.na(SampleDepthValue) & CharacteristicName=='Depth, data-logger (ported)')]
# Setting SampleDepthValue to NA for records w/ ActivityRelativeDepthName=='Bottom' & ActivityDepthHeight==0
wq_data[ActivityRelativeDepthName=='Bottom' & ActivityDepthHeightMeasure.MeasureValue==0,SampleDepthValue:=NA]
# Generating new RelativeDepth column for cases where both ActivityDepth and ResultDepth are NULL
wq_data[,RelativeDepth:=NA_character_]
wq_data[is.na(SampleDepthValue) & !is.na(ActivityRelativeDepthName),RelativeDepth:=ActivityRelativeDepthName]
wq_data[,.N,by=RelativeDepth]
# Extract times by site & date
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2215 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 1990 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1111 xx
site_date_starttime=unique(wq_data[,.(MonitoringLocationIdentifier,ActivityStartDate,ActivityStartTime.Time,ActivityStartTime.TimeZoneCode)])
dim(site_date_starttime) # 2630 xx
# Remove Time=NA
site_date_starttime=site_date_starttime[!is.na(ActivityStartTime.Time),]
dim(site_date_starttime) # 2405 xx
# Check timeszones
site_date_starttime[,.N,by=ActivityStartTime.TimeZoneCode]
#    ActivityStartTime.TimeZoneCode    N
# 1:                            MDT   17
# 2:                            MST 2386
# 3:                            EST    2
### Accepting all and set tz to 'America/Denver'.
# Add datetime
site_date_starttime[,datetime:=as.POSIXct(paste(ActivityStartDate,ActivityStartTime.Time),format='%Y-%m-%d %H:%M:%S',tz='America/Denver')]
# Filter for minimum time value
min(site_date_starttime$datetime) #
dim(site_date_starttime) # 1259 xx
site_date_starttime
site_date_starttime=site_date_starttime[,.(datetime=min(datetime)),by=.(MonitoringLocationIdentifier,ActivityStartDate)]
dim(site_date_starttime) # 1259 xx
# Add hour and minute
site_date_starttime[,hour:=hour(datetime)]
site_date_starttime[,minute:=minute(datetime)]
# Join unified time stamps back to data, by Site-Date
intersect(names(wq_data),names(site_date_starttime)) #
dim(wq_data) # 50829 xx
wq_data=merge(wq_data,site_date_starttime,by=c('MonitoringLocationIdentifier','ActivityStartDate'),all.x=T) # Left outer join
dim(wq_data) # 50829 xx
# Subset to relevant columns
cols_keep=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
# Subset to relevant columns xxx
tmp=c(
'OrganizationIdentifier','OrganizationFormalName','MonitoringLocationIdentifier','MonitoringLocationName','MonitoringLocationTypeName','LatitudeMeasure','LongitudeMeasure','HorizontalCoordinateReferenceSystemDatumName','ActivityStartDate',
# These are the columns that have been added through the code above
'SampleDepthUnit','SampleDepthValue','RelativeDepth','datetime','minute','hour',
'CharacteristicName','ResultSampleFractionText','ResultMeasureValue','ResultMeasure.MeasureUnitCode',
'MethodSpecificationName','MeasureQualifierCode','ResultDetectionConditionText',
'ResultStatusIdentifier','ResultValueTypeName','ActivityMediaName',
'EstimatedQuantitationLimit','LowerQuantitationLimit','LowerReportingLimit','MethodDetectionLevel',
'UpperQuantitationLimit','EstimatedQuantitationLimitUnit',
'LowerQuantitationLimitUnit','LowerReportingLimitUnit','MethodDetectionLevelUnit','UpperQuantitationLimitUnit'
)
rm(cols_keep)
wq_data=wq_data[,..tmp]
wq_data
# Extracting unique result value for each site, date, depth, parameter, & fraction
wq_data=unique(wq_data)
dim(wq_data) # 47114 xx
# Check for multiple result values by site, date, depth, parameter, & fraction
tmp=wq_data[,.(MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText)]
nrow(wq_data) - nrow(unique(tmp)) # 3265 multiple results
dim(tmp)
# Copy dataset and relevant fields
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 47114 xx
dim(result_count) # 43849 xx
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 43849 xx
result_count
tmp
# Copy dataset
tmp=c('MonitoringLocationIdentifier','datetime','SampleDepthValue','RelativeDepth','CharacteristicName','ResultSampleFractionText')
result_count=copy(wq_data[,..tmp])
dim(result_count) # 58369 xx
result_count
View(result_count)
# Count multiple results
result_count=result_count[,.(result_count=.N),by=tmp]
dim(result_count) # 54805 xx
dim(wq_data) # 47114 xx
# Join result_count (use all fields)
wq_data=merge(wq_data,result_count,by=tmp,all.x=T) # Left outer join
dim(wq_data) # 47114 xx
dim(wq_data) # 47114 xx
wq_data[,.N,by=result_count]
# Sort
setorder(wq_data,MonitoringLocationIdentifier,datetime,SampleDepthValue,RelativeDepth,CharacteristicName,ResultSampleFractionText,ResultMeasureValue)
# Save data. This will OVERWRITE existing data.
save(wq_data,file='ul_data.RData')
